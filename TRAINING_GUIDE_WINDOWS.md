# ğŸ§  Complete Model Training Guide for Windows

## ğŸš€ Quick Start Training

### **ğŸ“Š STEP 1: Prepare Your Dataset**

#### **Option A: Use Sample Data (For Testing)**
```cmd
# Use the existing sample dataset
python train_model.py --dataset data/sample_dataset.csv --sample-size 100
```

#### **Option B: Create Your Own Dataset**
Create a CSV file with this format:
```csv
url,label
https://www.google.com,0
https://github.com,0
http://paypal-security-alert.fake.com/login,1
http://amazon-account-suspended.scam.org/verify,1
https://stackoverflow.com,0
```

#### **Option C: Download Public Datasets**
```powershell
# Example: Download PhishTank data (you'll need to register)
# Save as data/new_phishing_dataset.csv
```

---

### **ğŸ”§ STEP 2: Basic Training Commands**

#### **ğŸ¯ Simple Training (Recommended First Try):**
```cmd
python train_model.py --dataset data/your_dataset.csv
```

#### **ğŸš€ Advanced Training with Options:**
```cmd
python train_model.py ^
    --dataset data/your_dataset.csv ^
    --model-type random_forest ^
    --compare-models ^
    --cross-validation
```

#### **âš¡ Quick Test Training (Small Dataset):**
```cmd
python train_model.py ^
    --dataset data/your_dataset.csv ^
    --sample-size 1000 ^
    --model-type random_forest
```

---

### **ğŸ›ï¸ STEP 3: Training Options Explained**

#### **ğŸ“Š Dataset Options:**
```cmd
--dataset path/to/file.csv          # Your dataset file
--url-column "website"              # If your URL column isn't named "url"
--label-column "is_phishing"        # If your label column isn't named "label"
--sample-size 5000                  # Use only part of dataset for testing
```

#### **ğŸ§  Model Type Options:**
```cmd
--model-type random_forest          # Good balance (recommended)
--model-type xgboost               # Best performance (if available)
--model-type gradient_boost        # Good alternative
--model-type logistic              # Fast training
--model-type svm                   # Good for small datasets
```

#### **ğŸ”¬ Advanced Options:**
```cmd
--compare-models                   # Test multiple models
--hyperparameter-tuning           # Optimize model parameters
--cross-validation                # Validate model performance
--output-dir models/new_model     # Save model to specific location
```

---

### **ğŸ“ˆ STEP 4: Training Examples by Use Case**

#### **ğŸ¯ Scenario 1: First Time Training**
```cmd
# Start simple with sample data
python train_model.py ^
    --dataset data/sample_dataset.csv ^
    --model-type random_forest ^
    --sample-size 50
```

#### **ğŸ­ Scenario 2: Production Training**
```cmd
# Full training with your dataset
python train_model.py ^
    --dataset data/my_phishing_data.csv ^
    --model-type random_forest ^
    --cross-validation
```

#### **ğŸ”¬ Scenario 3: Model Comparison**
```cmd
# Compare different algorithms
python train_model.py ^
    --dataset data/my_phishing_data.csv ^
    --compare-models ^
    --sample-size 10000
```

#### **âš¡ Scenario 4: Hyperparameter Optimization**
```cmd
# Find best parameters (slow but optimal)
python train_model.py ^
    --dataset data/my_phishing_data.csv ^
    --model-type random_forest ^
    --hyperparameter-tuning
```

#### **ğŸ“Š Scenario 5: Custom Column Names**
```cmd
# If your CSV has different column names
python train_model.py ^
    --dataset data/custom_data.csv ^
    --url-column "website_url" ^
    --label-column "is_malicious"
```

---

### **ğŸ“ STEP 5: Dataset Preparation Examples**

#### **ğŸ“ Create Sample Dataset Script:**
```cmd
# Save this as create_sample_data.py
```

```python
import pandas as pd

# Create sample data
urls = [
    ("https://www.google.com", 0),
    ("https://github.com", 0),
    ("https://stackoverflow.com", 0),
    ("http://paypal-verify.fake.com/login", 1),
    ("http://amazon-suspend.scam.org/verify", 1),
    ("http://microsoft-security.phish.net/update", 1),
    ("https://www.microsoft.com", 0),
    ("https://www.wikipedia.org", 0),
    ("http://facebook-alert.evil.com/signin", 1),
    ("http://google-suspended.fake.net/verify", 1)
]

df = pd.DataFrame(urls, columns=['url', 'label'])
df.to_csv('data/my_sample_dataset.csv', index=False)
print("âœ… Sample dataset created!")
```

#### **ğŸ”„ Run the Sample Data Creator:**
```cmd
python create_sample_data.py
```

---

### **âš™ï¸ STEP 6: Understanding Training Output**

#### **ğŸ“Š What You'll See During Training:**
```
ğŸ”§ Starting feature extraction...
ğŸ“Š Processed 1000/5000 URLs
âœ… Feature extraction complete. Shape: (5000, 40)
ğŸ§  Training random_forest model...
ğŸ“ˆ Test Accuracy: 85.6%
ğŸ“Š F1 Score: 72.3%
ğŸ¯ Model training complete!
ğŸ’¾ Model saved to models/phishing_detector.joblib
```

#### **ğŸ“‹ Training Results Include:**
- **Accuracy Metrics**: How well the model performs
- **Feature Importance**: Which URL patterns matter most
- **Confusion Matrix**: Breakdown of correct/incorrect predictions
- **Model Comparison**: If you used --compare-models

---

### **ğŸ” STEP 7: Advanced Training Scenarios**

#### **ğŸ”„ Retraining Existing Model:**
```cmd
# Backup current model first
copy models\phishing_detector.joblib models\backup_phishing_detector.joblib

# Train new model
python train_model.py ^
    --dataset data\new_dataset.csv ^
    --model-type random_forest
```

#### **ğŸ“Š Large Dataset Training:**
```cmd
# For datasets > 100k URLs
python train_model.py ^
    --dataset data\large_dataset.csv ^
    --model-type random_forest ^
    --sample-size 50000
```

#### **ğŸ¯ Model Performance Tuning:**
```cmd
# Optimize for best performance
python train_model.py ^
    --dataset data\training_data.csv ^
    --model-type random_forest ^
    --hyperparameter-tuning ^
    --cross-validation
```

---

### **ğŸ“ˆ STEP 8: Monitoring Training Progress**

#### **ğŸ“‹ Check Training Logs:**
```cmd
# View training progress
type training.log
```

#### **ğŸ“Š Model Performance Files:**
- **models/model_comparison.csv**: Compare different algorithms
- **models/training_report_[model].json**: Detailed training results
- **training.log**: Training progress and errors

---

### **ğŸ› ï¸ STEP 9: Troubleshooting**

#### **âŒ Common Issues:**

**Problem**: "Dataset file not found"
```cmd
# Solution: Check file path
dir data\
python train_model.py --dataset data\correct_filename.csv
```

**Problem**: "Column not found"
```cmd
# Solution: Check column names in your CSV
python -c "import pandas as pd; print(pd.read_csv('data/your_file.csv').columns.tolist())"
```

**Problem**: "Out of memory"
```cmd
# Solution: Use sample size
python train_model.py --dataset data\large_file.csv --sample-size 10000
```

**Problem**: "Training too slow"
```cmd
# Solution: Use random forest instead of SVM
python train_model.py --dataset data\file.csv --model-type random_forest
```

---

### **ğŸ¯ STEP 10: Production Deployment**

#### **ğŸ”„ Replace Current Model:**
```cmd
# Backup current model
copy models\phishing_detector.joblib models\backup\phishing_detector_backup.joblib

# Copy new model
copy models\new_model.joblib models\phishing_detector.joblib

# Test the new model
python test_model.py
```

#### **ğŸ§ª A/B Testing:**
```cmd
# Keep both models and compare
python train_model.py --dataset data\new_data.csv --output-dir models\experimental\
```

---

## ğŸ‰ Quick Training Checklist

1. âœ… **Prepare Dataset**: Create CSV with url,label columns
2. âœ… **Start Simple**: `python train_model.py --dataset data/file.csv`
3. âœ… **Check Results**: Look at accuracy in training output
4. âœ… **Test Model**: `python test_model.py` 
5. âœ… **Deploy**: Replace old model file
6. âœ… **Validate**: Test with web interface

## ğŸ“ Need Help?

- **ğŸ“‹ Check training logs**: `type training.log`
- **ğŸ” Test current model**: `python test_model.py`
- **ğŸŒ Verify web interface**: `python web_server.py`

**Happy training! ğŸ§ ğŸš€**
